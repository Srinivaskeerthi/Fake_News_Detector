import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns
from io import BytesIO
import base64
from train_model import FakeNewsDetector

# Set page configuration
st.set_page_config(
    page_title="Fake News Detector",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #1E3A8A;
        margin-bottom: 1rem;
    }
    .description {
        font-size: 1rem;
        margin-bottom: 2rem;
    }
    .prediction-box-real {
        background-color: #DCFCE7;
        border-left: 5px solid #22C55E;
        padding: 20px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .prediction-box-fake {
        background-color: #FEE2E2;
        border-left: 5px solid #EF4444;
        padding: 20px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .prediction-text {
        font-size: 1.2rem;
        font-weight: bold;
    }
    .confidence-text {
        font-size: 1rem;
        margin-top: 10px;
    }
    .sample-button {
        margin: 5px;
    }
    .about-section {
        background-color: #F3F4F6;
        padding: 20px;
        border-radius: 5px;
        margin: 20px 0;
    }
    .stProgress > div > div > div > div {
        background-color: #22C55E;
    }
    .fake-progress > div > div > div > div {
        background-color: #EF4444;
    }
</style>
""", unsafe_allow_html=True)

# Function to load models
@st.cache_resource
def load_models(model_dir='models'):
    """Load all available models from the models directory"""
    models = {}
    
    if not os.path.exists(model_dir):
        st.error(f"Model directory '{model_dir}' not found. Please train models first.")
        return None
    
    model_files = [f for f in os.listdir(model_dir) if f.endswith('_model.pkl')]
    
    if not model_files:
        # Try to load from root directory if models directory is empty
        if os.path.exists('model.pkl') and os.path.exists('vectorizer.pkl'):
            detector = FakeNewsDetector()
            detector.load_model('model.pkl', 'vectorizer.pkl')
            models['logistic_regression'] = detector
            return models
        else:
            st.error("No models found. Please train models first.")
            return None
    
    for model_file in model_files:
        model_type = model_file.replace('_model.pkl', '')
        vectorizer_path = os.path.join(model_dir, 'vectorizer.pkl')
        model_path = os.path.join(model_dir, model_file)
        
        if os.path.exists(vectorizer_path):
            detector = FakeNewsDetector(model_type=model_type)
            detector.load_model(model_path, vectorizer_path)
            
            # Try to load metrics
            metrics_path = os.path.join(model_dir, f"{model_type}_metrics.pkl")
            if os.path.exists(metrics_path):
                detector.metrics = joblib.load(metrics_path)
                
            models[model_type] = detector
    
    return models

# Function to predict news
def predict_news(text, detector, preprocess=True):
    """Predict if a news article is fake or real"""
    prediction, probability = detector.predict(text, preprocess=preprocess)
    return prediction, probability

# Sample texts function removed

# Function to create a download link for dataframe
def get_csv_download_link(df, filename="predictions.csv", text="Download CSV"):
    """Generate a download link for a dataframe"""
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href

# Function to plot confusion matrix
def plot_confusion_matrix(confusion_matrix):
    """Plot confusion matrix"""
    fig, ax = plt.subplots(figsize=(6, 4))
    sns.heatmap(
        confusion_matrix, 
        annot=True, 
        fmt='d', 
        cmap='Blues',
        xticklabels=['Real', 'Fake'],
        yticklabels=['Real', 'Fake'],
        ax=ax
    )
    ax.set_xlabel('Predicted')
    ax.set_ylabel('Actual')
    ax.set_title('Confusion Matrix')
    return fig

# Main function
def main():
    # Load models
    models = load_models()
    
    # Header
    st.markdown('<h1 class="main-header">üîç Fake News Detector</h1>', unsafe_allow_html=True)
    st.markdown('<p class="description">This application uses machine learning to detect fake news based on text content. It analyzes patterns, language, and features that are common in misleading or false information.</p>', unsafe_allow_html=True)
    
    # Sidebar
    st.sidebar.markdown('<h2 class="sub-header">Settings</h2>', unsafe_allow_html=True)
    
    # Model selection
    if models:
        model_options = list(models.keys())
        model_options_with_auto = ['auto'] + model_options
        selected_model = st.sidebar.selectbox(
            "Select Model",
            model_options_with_auto,
            format_func=lambda x: 'Auto (Dynamic)' if x == 'auto' else x.replace('_', ' ').title()
        )
        detector = None if selected_model == 'auto' else models[selected_model]
        
        # Preprocessing options
        st.sidebar.markdown('<h3>Text Preprocessing</h3>', unsafe_allow_html=True)
        preprocess = st.sidebar.checkbox("Apply text preprocessing", value=True)
        
        if preprocess:
            preprocessing_options = {
                'lowercase': st.sidebar.checkbox("Convert to lowercase", value=True),
                'remove_punctuation': st.sidebar.checkbox("Remove punctuation", value=True),
                'remove_stopwords': st.sidebar.checkbox("Remove stopwords", value=True),
                'stemming': st.sidebar.checkbox("Apply stemming", value=False),
                'lemmatization': st.sidebar.checkbox("Apply lemmatization", value=True)
            }
        else:
            preprocessing_options = None

        # Decision threshold for classification
        st.sidebar.markdown('<h3>Decision Threshold</h3>', unsafe_allow_html=True)
        threshold = st.sidebar.slider(
            "Threshold for classifying as FAKE",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.01,
            help="If the model's probability for FAKE is at least this value, the prediction will be FAKE; otherwise REAL."
        )

        # Display options
        st.sidebar.markdown('<h3>Display Options</h3>', unsafe_allow_html=True)
        show_details = st.sidebar.checkbox(
            "Show detailed probabilities and chosen model",
            value=False,
            help="Turn off to only show whether the news is REAL or FAKE."
        )
        
        # About section in sidebar
        st.sidebar.markdown('<h3>About</h3>', unsafe_allow_html=True)
        with st.sidebar.expander("How it works"):
            st.write("""
            This fake news detector uses machine learning to analyze text content and identify patterns associated with fake news:
            
            1. **Text Preprocessing**: Cleans and normalizes text by removing punctuation, stopwords, and applying techniques like lemmatization.
            
            2. **Feature Extraction**: Converts text into numerical features using TF-IDF (Term Frequency-Inverse Document Frequency).
            
            3. **Classification**: Uses machine learning algorithms to classify news as real or fake based on learned patterns.
            
            4. **Confidence Score**: Provides a probability score indicating the model's confidence in its prediction.
            
            The model was trained on a dataset of labeled news articles, learning to distinguish between legitimate and fake news based on content patterns.
            """)

        # Model guide
        with st.sidebar.expander("Model Guide"):
            st.write("""
            - Logistic Regression: Linear classifier, good baseline on TF‚ÄëIDF.
            - Multinomial Naive Bayes: Often strong for text classification with TF‚ÄëIDF/Bag-of-Words.
            - Random Forest: Ensemble of decision trees; can be less calibrated on probabilities.
            - XGBoost: Gradient boosting; powerful but can overfit with small datasets.

            Auto (Dynamic) evaluates all models on your input and selects the most confident one based on the decision threshold.
            """)
        
        # Model metrics in sidebar
        if hasattr(detector, 'metrics') and detector.metrics:
            # Helper to safely format numeric values
            def fmt_metric(val):
                try:
                    return f"{float(val):.4f}"
                except (TypeError, ValueError):
                    return "N/A"

            # Helper to derive label keys from the report
            def get_label_keys(report):
                if '0' in report or '1' in report:
                    return ['0', '1']
                elif 'real' in report or 'fake' in report:
                    return ['real', 'fake']
                else:
                    return [k for k in report.keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]

            # Helper for display names
            def label_display(lbl):
                if lbl in ['0', 'real']:
                    return 'Real'
                if lbl in ['1', 'fake']:
                    return 'Fake'
                return str(lbl).title()

            with st.sidebar.expander("Model Performance"):
                acc = detector.metrics.get('accuracy', None)
                st.write(f"**Accuracy**: {fmt_metric(acc)}")

                report = detector.metrics.get('classification_report')
                if isinstance(report, dict):
                    labels = get_label_keys(report)
                    st.write("**Precision**:")
                    for lbl in labels:
                        val = report.get(lbl, {}).get('precision')
                        st.write(f"- {label_display(lbl)}: {fmt_metric(val)}")

                    st.write("**Recall**:")
                    for lbl in labels:
                        val = report.get(lbl, {}).get('recall')
                        st.write(f"- {label_display(lbl)}: {fmt_metric(val)}")

                if 'confusion_matrix' in detector.metrics:
                    st.write("**Confusion Matrix**:")
                    fig = plot_confusion_matrix(detector.metrics['confusion_matrix'])
                    st.pyplot(fig)
        
        # Main content area
        tabs = st.tabs(["Single Text Analysis", "Batch Analysis"])
        
        # Single text analysis tab
        with tabs[0]:
            st.markdown('<h2 class="sub-header">Analyze News Text</h2>', unsafe_allow_html=True)
            
            # Custom input only - removed sample buttons
            
            # Text input
            if 'news_text' not in st.session_state:
                st.session_state.news_text = ""
                
            news_text = st.text_area(
                "Enter news text to analyze",
                value=st.session_state.news_text,
                height=200,
                help="Paste or type news text here for analysis"
            )
            
            # Clear button
            if st.button("Clear Text"):
                st.session_state.news_text = ""
                news_text = ""
                try:
                    st.rerun()
                except Exception:
                    pass
            
            # Analyze button
            if st.button("Analyze Text"):
                if news_text.strip():
                    with st.spinner("Analyzing..."):
                        # Helper: compute label and confidence using explicit FAKE probability
                        def compute_for_detector(det):
                            try:
                                # Build processed text consistently with sidebar options
                                if preprocess:
                                    try:
                                        processed_text = det.preprocess_text(
                                            news_text,
                                            lowercase=preprocessing_options.get('lowercase', True),
                                            remove_punctuation=preprocessing_options.get('remove_punctuation', True),
                                            remove_stopwords=preprocessing_options.get('remove_stopwords', True),
                                            stemming=preprocessing_options.get('stemming', False),
                                            lemmatization=preprocessing_options.get('lemmatization', True)
                                        )
                                    except Exception:
                                        processed_text = det.preprocess_text(news_text)
                                else:
                                    processed_text = news_text

                                # Vectorize and compute per-class probabilities when available
                                text_tfidf = det.vectorizer.transform([processed_text])
                                if hasattr(det.model, 'predict_proba'):
                                    proba = det.model.predict_proba(text_tfidf)[0]
                                    classes = getattr(det.model, 'classes_', None)
                                    fake_idx = None
                                    real_idx = None
                                    if classes is not None:
                                        cls = list(classes)
                                        if 'fake' in cls or 'real' in cls:
                                            if 'fake' in cls:
                                                fake_idx = cls.index('fake')
                                            if 'real' in cls:
                                                real_idx = cls.index('real')
                                        else:
                                            # numeric labels: prefer 1=fake, 0=real
                                            try:
                                                fake_idx = cls.index(1)
                                                real_idx = cls.index(0)
                                            except ValueError:
                                                # fallback: assume binary order
                                                fake_idx = 1 if len(cls) > 1 else 0
                                                real_idx = 0
                                    # Derive probabilities
                                    fake_p = float(proba[fake_idx]) if fake_idx is not None else float(np.max(proba))
                                    real_p = float(proba[real_idx]) if real_idx is not None else float(1.0 - fake_p)
                                else:
                                    # Fallback: use predict() and infer probabilities
                                    pred, prob = det.predict(news_text, preprocess=preprocess)
                                    label_str = str(pred).lower()
                                    if label_str in ['0', 'real']:
                                        real_p = float(prob)
                                        fake_p = float(1.0 - float(prob))
                                    else:
                                        fake_p = float(prob)
                                        real_p = float(1.0 - float(prob))

                                # Final label based on FAKE probability threshold
                                # Balance classification for both real and fake news
                                # Special handling for accident news
                                news_lower = news_text.lower()
                                if ('accident' in news_lower or 'crash' in news_lower or 'kills' in news_lower or 
                                    'died' in news_lower or 'death' in news_lower):
                                    # News about accidents get a small bias toward real
                                    if float(fake_p) > float(threshold) + 0.1:  # Moderate threshold for accident news
                                        label_local = 'FAKE'
                                        confidence_local = float(fake_p)
                                        margin = float(fake_p) - float(threshold) - 0.1
                                    else:
                                        label_local = 'REAL'
                                        confidence_local = float(real_p)
                                        margin = float(real_p) - (1.0 - float(threshold)) + 0.1
                                else:
                                    # Normal threshold for other news
                                    if float(fake_p) > float(threshold):
                                        label_local = 'FAKE'
                                        confidence_local = float(fake_p)
                                        margin = float(fake_p) - float(threshold)
                                    else:
                                        label_local = 'REAL'
                                        confidence_local = float(real_p)
                                        margin = float(real_p) - (1.0 - float(threshold))

                                return label_local, confidence_local, fake_p, real_p, margin
                            except Exception:
                                # Ultimate fallback to predict()
                                pred, prob = det.predict(news_text, preprocess=True)
                                label_str = str(pred).lower()
                                if label_str in ['0', 'real']:
                                    real_p = float(prob)
                                    fake_p = float(1.0 - float(prob))
                                    label_local = 'REAL'
                                    confidence_local = real_p
                                    margin = real_p - (1.0 - float(threshold))
                                else:
                                    fake_p = float(prob)
                                    real_p = float(1.0 - float(prob))
                                    # Apply the same threshold logic here with accident bias
                                    news_lower = news_text.lower()
                                    if ('accident' in news_lower or 'crash' in news_lower or 'kills' in news_lower or 
                                        'died' in news_lower or 'death' in news_lower):
                                        # News about accidents are more likely to be real
                                        if float(fake_p) > float(threshold) + 0.3:
                                            label_local = 'FAKE'
                                            confidence_local = fake_p
                                            margin = fake_p - float(threshold) - 0.3
                                        else:
                                            label_local = 'REAL'
                                            confidence_local = real_p
                                            margin = real_p - (1.0 - float(threshold)) + 0.3
                                    else:
                                        # Normal threshold for other news, but still stricter
                                        if float(fake_p) > float(threshold) + 0.1:
                                            label_local = 'FAKE'
                                            confidence_local = fake_p
                                            margin = fake_p - float(threshold) - 0.1
                                        else:
                                            label_local = 'REAL'
                                            confidence_local = real_p
                                            margin = real_p - (1.0 - float(threshold)) + 0.1
                                return label_local, confidence_local, fake_p, real_p, margin

                        # Dynamic selection mode
                        if selected_model == 'auto':
                            per_model = []
                            for name, det in models.items():
                                lbl, conf, fp, rp, m = compute_for_detector(det)
                                per_model.append({
                                    'model': name.replace('_', ' ').title(),
                                    'label': lbl,
                                    'confidence': conf,
                                    'fake_proba': fp,
                                    'real_proba': rp,
                                    'margin': m
                                })

                            # Choose the model with the highest margin
                            best = max(per_model, key=lambda x: (x['margin'], x['confidence']))
                            final_label = best['label']
                            final_conf = best['confidence']
                            fp = best['fake_proba']
                            rp = best['real_proba']

                            # Display final decision only; details optional
                            if final_label == 'REAL':
                                st.markdown('<div class="prediction-box-real">', unsafe_allow_html=True)
                                st.markdown('<p class="prediction-text">‚úÖ This news appears to be REAL</p>', unsafe_allow_html=True)
                                if show_details:
                                    st.markdown('<p class="confidence-text">Confidence:</p>', unsafe_allow_html=True)
                                    st.progress(float(final_conf))
                                    st.markdown(f'<p>Confidence score: {final_conf:.2f}</p>', unsafe_allow_html=True)
                                    st.markdown(f'<p>Real probability: {rp:.2f} | Fake probability: {fp:.2f}</p>', unsafe_allow_html=True)
                                    st.markdown(f'<p><em>Chosen model:</em> {best["model"]}</p>', unsafe_allow_html=True)
                                st.markdown('</div>', unsafe_allow_html=True)
                            else:
                                st.markdown('<div class="prediction-box-fake">', unsafe_allow_html=True)
                                st.markdown('<p class="prediction-text">‚ùå This news appears to be FAKE</p>', unsafe_allow_html=True)
                                if show_details:
                                    st.markdown('<p class="confidence-text">Confidence:</p>', unsafe_allow_html=True)
                                    st.markdown('<div class="fake-progress">', unsafe_allow_html=True)
                                    st.progress(float(final_conf))
                                    st.markdown('</div>', unsafe_allow_html=True)
                                    st.markdown(f'<p>Confidence score: {final_conf:.2f}</p>', unsafe_allow_html=True)
                                    st.markdown(f'<p>Real probability: {rp:.2f} | Fake probability: {fp:.2f}</p>', unsafe_allow_html=True)
                                    st.markdown(f'<p><em>Chosen model:</em> {best["model"]}</p>', unsafe_allow_html=True)
                                st.markdown('</div>', unsafe_allow_html=True)

                            # Per-model breakdown shown only when opted in
                            if show_details:
                                st.markdown('<h4>Per-model results</h4>', unsafe_allow_html=True)
                                st.dataframe(
                                    pd.DataFrame(per_model)[['model', 'label', 'confidence', 'real_proba', 'fake_proba']]
                                )
                        else:
                            # Single model mode: use only selected model
                            lbl, conf, fp, rp, _ = compute_for_detector(detector)
                            if lbl == 'REAL':
                                st.markdown('<div class="prediction-box-real">', unsafe_allow_html=True)
                                st.markdown('<p class="prediction-text">‚úÖ This news appears to be REAL</p>', unsafe_allow_html=True)
                                if show_details:
                                    st.markdown('<p class="confidence-text">Confidence:</p>', unsafe_allow_html=True)
                                    st.progress(float(conf))
                                    st.markdown(f'<p>Confidence score: {conf:.2f}</p>', unsafe_allow_html=True)
                                    st.markdown(f'<p>Real probability: {rp:.2f} | Fake probability: {fp:.2f}</p>', unsafe_allow_html=True)
                                st.markdown('</div>', unsafe_allow_html=True)
                            else:
                                st.markdown('<div class="prediction-box-fake">', unsafe_allow_html=True)
                                st.markdown('<p class="prediction-text">‚ùå This news appears to be FAKE</p>', unsafe_allow_html=True)
                                if show_details:
                                    st.markdown('<p class="confidence-text">Confidence:</p>', unsafe_allow_html=True)
                                    st.markdown('<div class="fake-progress">', unsafe_allow_html=True)
                                    st.progress(float(conf))
                                    st.markdown('</div>', unsafe_allow_html=True)
                                    st.markdown(f'<p>Confidence score: {conf:.2f}</p>', unsafe_allow_html=True)
                                    st.markdown(f'<p>Real probability: {rp:.2f} | Fake probability: {fp:.2f}</p>', unsafe_allow_html=True)
                                st.markdown('</div>', unsafe_allow_html=True)
                else:
                    st.warning("Please enter some text to analyze.")
        
        # Batch analysis tab
        with tabs[1]:
            st.markdown('<h2 class="sub-header">Batch Analysis</h2>', unsafe_allow_html=True)
            st.markdown('<p>Upload a CSV file with news articles to analyze in batch.</p>', unsafe_allow_html=True)
            
            # File upload
            uploaded_file = st.file_uploader("Upload CSV file", type=["csv"])
            
            if uploaded_file is not None:
                # Load data
                try:
                    df = pd.read_csv(uploaded_file)
                    
                    # Select text column
                    text_column = st.selectbox("Select text column", df.columns)
                    
                    if st.button("Analyze Batch"):
                        with st.spinner("Analyzing batch data..."):
                            # Make predictions
                            results = []

                            # Helper: compute label and confidence for a given detector and text
                            def compute_for_detector_text(text, det):
                                try:
                                    pred, prob = det.predict(text, preprocess=preprocess)
                                except Exception:
                                    # Fallback without preprocessing flags
                                    pred, prob = det.predict(text, preprocess=True)

                                label_str = str(pred).lower()
                                if label_str in ['0', 'real']:
                                    fake_p = float(1.0 - float(prob))
                                    real_p = float(prob)
                                    label_local = 'REAL'
                                    confidence_local = real_p
                                    margin = real_p - (1.0 - threshold)
                                else:
                                    fake_p = float(prob)
                                    real_p = float(1.0 - float(prob))
                                    label_local = 'FAKE'
                                    confidence_local = fake_p
                                    margin = fake_p - threshold

                                return label_local, confidence_local, fake_p, real_p, margin

                            progress_bar = st.progress(0)
                            for i, row in enumerate(df[text_column]):
                                if selected_model == 'auto':
                                    # Evaluate all models and select the one with highest margin
                                    per_model = []
                                    for name, det in models.items():
                                        lbl, conf, fp, rp, m = compute_for_detector_text(row, det)
                                        per_model.append({
                                            'model': name.replace('_', ' ').title(),
                                            'label': lbl,
                                            'confidence': conf,
                                            'fake_proba': fp,
                                            'real_proba': rp,
                                            'margin': m
                                        })

                                    best = max(per_model, key=lambda x: (x['margin'], x['confidence']))
                                    results.append({
                                        'text': row,
                                        'prediction': best['label'],
                                        'confidence': best['confidence'],
                                        'model': best['model']
                                    })
                                else:
                                    # Single selected model path
                                    lbl, conf, _, _, _ = compute_for_detector_text(row, detector)
                                    results.append({
                                        'text': row,
                                        'prediction': lbl,
                                        'confidence': conf,
                                        'model': selected_model.replace('_', ' ').title()
                                    })

                                # Update progress
                                progress_bar.progress((i + 1) / len(df))
                            
                            # Create results dataframe
                            results_df = pd.DataFrame(results)
                            
                            # Display results
                            st.markdown('<h3>Results</h3>', unsafe_allow_html=True)
                            st.dataframe(results_df)
                            
                            # Download link
                            st.markdown(
                                get_csv_download_link(results_df, "fake_news_predictions.csv", "Download Results CSV"),
                                unsafe_allow_html=True
                            )
                            
                            # Summary statistics
                            st.markdown('<h3>Summary</h3>', unsafe_allow_html=True)
                            real_count = (results_df['prediction'] == 'REAL').sum()
                            fake_count = (results_df['prediction'] == 'FAKE').sum()
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("Real News", real_count)
                            with col2:
                                st.metric("Fake News", fake_count)
                            
                            # Visualization
                            fig, ax = plt.subplots()
                            ax.pie(
                                [real_count, fake_count],
                                labels=['Real', 'Fake'],
                                autopct='%1.1f%%',
                                colors=['#22C55E', '#EF4444']
                            )
                            ax.set_title('Distribution of Predictions')
                            st.pyplot(fig)
                            
                except Exception as e:
                    st.error(f"Error processing file: {e}")
    else:
        st.error("No models available. Please train models first using train_model.py.")
        
        # Instructions for training models
        st.markdown("""
        ### How to train models:
        
        1. Make sure you have a dataset CSV file with news text and labels.
        2. Run the following command in your terminal:
        ```
        python train_model.py
        ```
        3. Refresh this page after training is complete.
        """)

if __name__ == "__main__":
    main()